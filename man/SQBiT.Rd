% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SQBiT.R
\name{SQBiT}
\alias{SQBiT}
\title{Smoothed Quantile Bivariate Triangulation (SQBiT)}
\usage{
SQBiT(
  h = 7 * tau * (1 - tau) * ((ncol(C) + dim(Q2)[2] * ncol(X) +
    log(length(Y)))/length(Y))^(2/5),
  tau,
  Y,
  C,
  X,
  P,
  B,
  Q2,
  max.iter = 50,
  lambda,
  eps.abs = 1e-04,
  eps.rel = 0.01,
  var.j = FALSE,
  zeta = 10,
  incr = 2,
  eta.j = 0.32,
  interval = FALSE,
  level = 0.05,
  cond.est = FALSE,
  adaptive.h = FALSE,
  cc = 0.8,
  gacv.compute = TRUE
)
}
\arguments{
\item{h}{smoothing bandwidth}

\item{tau}{quantile level}

\item{Y}{response variable}

\item{C}{covariates with constant effects}

\item{X}{covariates with varying coefficients}

\item{P}{Penalty matrix. See examples. It is based on output from basis() in package BPST.}

\item{B}{Bernstein basis polynoimials. An object from basis() in package BPST.}

\item{Q2}{Q2 matrix from the QR decomposition of the smoothness matrix of triangles}

\item{max.iter}{maximum iterations for ADMM to converge}

\item{lambda}{penalization parameter}

\item{eps.abs}{first convergence criterion of ADMM}

\item{eps.rel}{second convergence criterion of ADMM}

\item{var.j}{whether to vary the step size in the ADMM}

\item{zeta}{criterion for the step size to increment if stepsize is set to vary}

\item{incr}{factor of increment for step size if stepsize is set to vary}

\item{eta.j}{step size. Set it to be 1 if vary.j = TRUE}

\item{interval}{whether to compute asymptotic confidence intervals for constant coefficients (TRUE/FALSE)}

\item{level}{significance level}

\item{cond.est}{external input of the conditional density (FALSE if no external input, a vector of conditional density if there is external input)}

\item{adaptive.h}{whether to use an adaptive choice of bandwidth used for conditional density estimation}

\item{cc}{the rule of thumb for adaptive choice of bandwidth used for conditional density estimation}

\item{gacv.compute}{whether to compute GACV}
}
\value{
A list with components:
\describe{
\item{\code{gamma}}{Spline coefficients.}
\item{\code{theta}}{Basis coefficients (\code{Q2 \%*\% gamma}).}
\item{\code{beta}}{Estimated varying coefficients.}
\item{\code{eta}}{Estimated constant coefficients.}
\item{\code{cis}}{Asymptotic intervals for the constant coefficients.}
\item{\code{ses}}{Estimated asymptotic standard errors.}
\item{\code{iter}}{Number of iterations used for convergence.}
\item{\code{time}}{Computational time used.}
\item{\code{gacv}}{The GACV of the estimated QSM; returns multiple values if multiple penalization parameters are used.}
}
}
\description{
This function performs the point estimation of quantile spatial model (QSM) with a given penalization parameter using SQBiT. It returns estimates for the constant coefficients, varying coefficients, and confidence intervals for the constant coefficients. SQBiT employs convolution smoothing based on uniform kernel and estimates the asymptotic covariance matrix using kernel density estimation based on uniform kernel.
}
\details{
\strong{What is Quantile Spatial Model (QSM)?}

The proposed Quantile Spatial Model (QSM) is given by:
\deqn{
Q_{\tau}(Y_i \mid \mathbf{C}_i,\mathbf{X}_i, \mathbf{S}_i) = \mathbf{C}_i^{\top} \boldsymbol{\eta}_{\tau}
+ \sum_{j=0}^p X_{ij} \beta_{j,\tau}(\mathbf{S}_i), \quad i = 1, \ldots, n.
}
where \eqn{Q_Y(\tau \mid \cdot) = \inf\{y: P(Y \leq y \mid \cdot) \geq \tau\}} denotes the
\eqn{\tau}th (\eqn{\tau \in (0, 1)}) conditional quantile of \eqn{Y},
\eqn{\boldsymbol{\eta}_{\tau} = (\eta_{1,\tau}, \ldots, \eta_{q,\tau})^{\top}} captures the constant effects,
and \eqn{\beta_{j,\tau} \colon \Omega \mapsto \mathbb{R}} is the unknown spatially varying coefficient function.
\cr

This semi-parametric model captures spatial heterogeneity through the spatially varying
coefficients \eqn{\beta_{j,\tau}(\cdot)}, and non-spatial covariate effects through the
constant coefficients \eqn{\eta_{\ell,\tau}}. The partially linear nature of the model offers both flexibility and interpretability.

\strong{How to use QSM?}:

In general, there are four steps to analyze spatial data using QSM.
\enumerate{
\item Create a triangulation mesh for your spatial domain. This can be done using "Triangulation" package. It can be downloaded in github using install_github("funstatpackages/Triangulation").
\item Generate the bivariate triangulation spline given a degree of polynomials \eqn{d} and a smoothness parameter \eqn{r}. This can be done using "BPST". It can be downloaded in github using install_github("FIRST-Data-Lab/BPST").
\item Fit QSM using SQBiT.
\item Plot the estimates for the varying coefficient.
}

\strong{Optimization}:

The optimization is based on alternating direction method of multipliers (ADMM). For the algorithmic details, we refer users to Boyd et al (2011). Note that it has been shown that the algorithm will converge under mild conditions even if a fixed step size is used for ADMM.
}
\examples{
\donttest{
###### Step 1. Create a Triangulation Mesh
boundaries <- matrix(c(0, 0,
                       0, 1,
                       1, 1,
                       1, 0), nrow = 4, byrow = TRUE)
tri <- TriMesh(boundaries, n = 8)
Tr <- tri$Tr
V <- round(tri$V, 3)

# Population locations
s1 <- runif(10000)
s2 <- runif(10000)
S_pop <- data.frame(s1 = s1, s2 = s2)

# Determine which points are inside triangulation
ind1 <- inVT(V0 = V, Tr0 = Tr, xx = S_pop[,1], yy = S_pop[,2])
ind1 <- ind1$ind.inside
ind2 <- (1:nrow(S_pop))[!is.na(S_pop[,1])]
ind <- sort(intersect(ind1, ind2))
pop.r <- S_pop[ind, ]
Npop <- nrow(pop.r)

# Coordinates and coefficient functions
S.pop <- pop.r[, c(1, 2)]
beta1 <- function(s1, s2) sin(pi * s1 * s2)
beta2 <- function(s1, s2) (1 - (1 - 2 * s1)^2) * (1 - (1 - 2 * s2)^2)
pop.r <- cbind(S.pop, beta1(S.pop[,1], S.pop[,2]), beta2(S.pop[,1], S.pop[,2]))
colnames(pop.r)[3:4] <- c('beta0', 'beta1')

####### Step 2. Generate bivariate triangulation basis
d <- 3
r <- 1
B0.pop <- basis(V = V, Tr = Tr, d = d, r = r, Z = as.matrix(S.pop))
Q2 <- B0.pop$Q2
B.pop <- B0.pop$B
K <- B0.pop$K
P <- t(Q2) \%*\% K \%*\% Q2

# Simulation parameters
n <- 2000
tau <- 0.5
eta <- matrix(c(1, 1, 1))
Sigma <- diag(3)

# Sample population and simulate covariates
ind.s <- sample(1:Npop, n)
data <- as.matrix(pop.r[ind.s, ])
S <- data[, c(1, 2)]
C <- matrix(runif(3 * n, -1, 1), ncol = 3)
X <- matrix(runif(n, -1, 1), n, 1)
beta0 <- data[, c('beta0', 'beta1')]
Y <- beta0[,1] + X[,1] * beta0[,2] + C \%*\% eta + rnorm(n = n)

####### Step 3. Estimate QSM using SQBiT
X <- cbind(1, X)
B <- B.pop[ind.s, ]
mod <- SQBiT(Y = Y, X = X, C = C, P = P, B = B, Q2 = Q2, lambda = 0.1, tau = tau)

####### Step 4. Plot varying coefficient
p <- ncol(X)
q <- ncol(C)
Jn <- dim(B.pop \%*\% Q2)[2]
mhat.sm <- c()
for(i in 1:p){
 mhat.sm <- cbind(mhat.sm, BQ2.pop \%*\% mod$gamma[(1 + (i - 1) * Jn):(Jn * i)])
}
interp_result <- interp(x = S.pop[, 1], y = S.pop[, 2], duplicate = "mean",
                       z = mhat.sm[, 2], nx = 140, ny = 140)
interp_df <- with(interp_result, expand.grid(x = x, y = y))
interp_df$z <- as.vector(interp_result$z)

# Plot smooth heatmap
ggplot(interp_df, aes(x = x, y = y, fill = z)) +
 geom_raster(interpolate = TRUE) +
 scale_fill_gradient(limits = c(0, 1),
                     low = "deepskyblue",
                     high = "magenta",
                     oob = scales::squish) +
 labs(
   x = "$s_1$",
   y = "$s_2$",
   z = "$\\\\beta_1(\\\\boldsymbol{s})$",
   fill = "$\\\\beta_1(\\\\boldsymbol{s})$"
 ) +
 coord_fixed() +
 theme_minimal() +
 theme(panel.grid = element_blank(),
       plot.title = element_text(hjust = 0.5))
}

}
\references{
Kim, M., Wang, L., and Wang, H. J. (2025). Estimation and inference of quantile spatially varying coefficient models over complicated domains. \emph{Journal of the American Statistical Association}, 1--15. Taylor & Francis. Forthcoming.

He, X., Pan, X., Tan, K.M., & Zhou, W.-X. (2023). Smoothed quantile regression with large-scale inference. \emph{Journal of Econometrics}, 232(2), 367â€“388.

Boyd, S., Parikh, N., Chu, E., Peleato, B., Eckstein, J., and others (2011). Distributed optimization and statistical learning via the alternating direction method of multipliers. \emph{Foundations and Trends in Machine Learning}, 3(1), 1--122. Now Publishers.
}
